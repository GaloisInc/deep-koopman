{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search for StatePredictor on NACA0012 data\n",
    "Do this tutorial after [`run.ipynb`](./run.ipynb).\n",
    "\n",
    "You might be wondering how we arrived at the input configurations in the 'Optimizing' and the 'Improving run time' sections in `run.ipynb`. The method `deepk.hyp_search:run_hyp_search()` can perform hyperparameter search on either `StatePredictor` or `TrajectoryPredictor`. This sweeps the values of the different inputs to the class and its methods. Each configuration is trained and the loss and ANAE statistics across epochs recorded for training data (and validation data, if provided). These results can then be used to select 'good' input configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepk.hyp_search import run_hyp_search\n",
    "from deepk.state_predictor import StatePredictor_DataHandler\n",
    "from deepk import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of Data Handler we create determines the predictor model on which hyperparameter search is performed. In this case, we create a `StatePredictor_DataHandler`. This automatically sets the hyperparameter search to run on `StatePredictor` models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = StatePredictor_DataHandler(\n",
    "    Xtr=data['Xtr'], ttr=data['ttr'],\n",
    "    Xva=data['Xva'], tva=data['tva']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that test data is not used in hyperparameter search. It is recommended to provide validaion data, so that validation loss and ANAE statistics can also be collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options for hyperparameter search\n",
    "The `StatePredictor` class has possible inputs:\n",
    "- `dh`\n",
    "- `rank`\n",
    "- `encoded_size`\n",
    "- `encoder_hidden_layers`\n",
    "- `decoder_hidden_layers`\n",
    "- `batch_norm`\n",
    "\n",
    "Its `train_net()` method has possible inputs:\n",
    "- `numepochs`\n",
    "- `early_stopping`\n",
    "- `early_stopping_metric`\n",
    "- `lr`\n",
    "- `weight_decay`\n",
    "- `decoder_loss_weight`\n",
    "- `Kreg`\n",
    "- `cond_threshold`\n",
    "- `clip_grad_norm`\n",
    "- `clip_grad_value`\n",
    "\n",
    "All of these inputs, with the exception of `dh` already defined above, can be swept together in the hyperparameter search.\n",
    "\n",
    "For more on the inputs, see the [documentation of `StatePredictor`](htps://TODO).\n",
    "\n",
    "Let us define some values to sweep over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_options = {\n",
    "    'encoded_size': 50, # 1 option\n",
    "    'encoder_hidden_layers': [ [100,100], [200,100,50] ], # 2 options\n",
    "    'numepochs': [100, 200, 300], # 3 options\n",
    "    'weight_decay': 1e-5 # 1 option\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options that are not provided will revert to defaults."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run hyperparameter search\n",
    "Let us now run the hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rank' is a required argument to StatePredictor, so 'hyp_options' must include a key-value pair for {'rank': <rank_values>}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    run_hyp_search(\n",
    "        dh = dh,\n",
    "        hyp_options = hyp_options\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh, you got a `ValueError: 'rank' is a required argument to StatePredictor, so 'hyp_options' must include a key-value pair for {'rank': <rank_values>}`. As it says, we need to specify one or more options for `rank` since this is a required argument that does not have a default value. Let us specify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_options['rank'] = [4, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hyp_options` now has a total of 12 options = 2 for `'rank'` times 2 for `'encoder_hidden_layers'` times 3 for `'numepochs'`. Let us run it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************************\n",
      "Starting StatePredictor hyperparameter search. Results will be stored in /Users/sourya/work/Essence/deep-koopman/examples/naca0012/hyp_search_6uznr5nGFUAnAFSisJZaEP/hyp_search_results.csv.\n",
      "\n",
      "Performing total 12 runs. You can interrupt the script at any time (e.g. Ctrl+C), and intermediate results will be available in the above file.\n",
      "\n",
      "Log of the entire hyperpaameter search, as well as logs of failed StatePredictor runs will also be stored in the same folder.\n",
      "\n",
      "Hyperparameters' sweep ranges:\n",
      "rank : 4, 6\n",
      "encoded_size : 50\n",
      "encoder_hidden_layers : [100, 100], [200, 100, 50]\n",
      "numepochs : 100, 200, 300\n",
      "weight_decay : 1e-05\n",
      "********************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 74.11it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 77.98it/s]\n",
      "100%|██████████| 300/300 [00:03<00:00, 75.10it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 71.49it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 67.00it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 60.30it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 76.81it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 73.56it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 72.55it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 64.73it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 70.18it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 73.51it/s]\n",
      "100%|██████████| 12/12 [00:34<00:00,  2.83s/it]\n"
     ]
    }
   ],
   "source": [
    "output_folder = run_hyp_search(\n",
    "    dh = dh,\n",
    "    hyp_options = hyp_options\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Hooray, it now runs successfully and returns a path to a folder. This contains a file `hyp_search_results.csv`. Let us open it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "      <th>rank</th>\n",
       "      <th>encoder_hidden_layers</th>\n",
       "      <th>numepochs</th>\n",
       "      <th>avg_recon_loss_tr</th>\n",
       "      <th>final_recon_loss_tr</th>\n",
       "      <th>avg_recon_loss_va</th>\n",
       "      <th>best_recon_loss_va</th>\n",
       "      <th>bestep_recon_loss_va</th>\n",
       "      <th>avg_lin_loss_tr</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_lin_anae_tr</th>\n",
       "      <th>final_lin_anae_tr</th>\n",
       "      <th>avg_lin_anae_va</th>\n",
       "      <th>best_lin_anae_va</th>\n",
       "      <th>bestep_lin_anae_va</th>\n",
       "      <th>avg_pred_anae_tr</th>\n",
       "      <th>final_pred_anae_tr</th>\n",
       "      <th>avg_pred_anae_va</th>\n",
       "      <th>best_pred_anae_va</th>\n",
       "      <th>bestep_pred_anae_va</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RjoHq8UdW3nrGLVM7ypCwT</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>195</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>...</td>\n",
       "      <td>5.749075</td>\n",
       "      <td>0.447996</td>\n",
       "      <td>12.580232</td>\n",
       "      <td>1.595680</td>\n",
       "      <td>61</td>\n",
       "      <td>170.359142</td>\n",
       "      <td>41.137810</td>\n",
       "      <td>369.384500</td>\n",
       "      <td>133.523148</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2i5bqBnxRqbbBTQxTHv52L</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.016442</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>299</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>...</td>\n",
       "      <td>6.168933</td>\n",
       "      <td>0.929518</td>\n",
       "      <td>32.996355</td>\n",
       "      <td>2.990858</td>\n",
       "      <td>35</td>\n",
       "      <td>129.926650</td>\n",
       "      <td>32.684006</td>\n",
       "      <td>188.648688</td>\n",
       "      <td>64.504990</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LEDBapbdDM3tEYbK2ewKgx</td>\n",
       "      <td>6</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.012588</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>...</td>\n",
       "      <td>19.242707</td>\n",
       "      <td>1.750130</td>\n",
       "      <td>66.426500</td>\n",
       "      <td>4.598801</td>\n",
       "      <td>35</td>\n",
       "      <td>104.343127</td>\n",
       "      <td>28.304497</td>\n",
       "      <td>203.419064</td>\n",
       "      <td>50.927658</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UWFcU3QYqPW3M5DtEWUnRX</td>\n",
       "      <td>4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>297</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>...</td>\n",
       "      <td>4.595422</td>\n",
       "      <td>0.188614</td>\n",
       "      <td>18.033944</td>\n",
       "      <td>1.376639</td>\n",
       "      <td>75</td>\n",
       "      <td>73.100246</td>\n",
       "      <td>24.763781</td>\n",
       "      <td>125.523613</td>\n",
       "      <td>53.717072</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KzEqFfihqt86dAN2itm8sT</td>\n",
       "      <td>6</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>...</td>\n",
       "      <td>7.635712</td>\n",
       "      <td>0.833945</td>\n",
       "      <td>26.515012</td>\n",
       "      <td>3.888892</td>\n",
       "      <td>61</td>\n",
       "      <td>164.118183</td>\n",
       "      <td>37.730003</td>\n",
       "      <td>261.344573</td>\n",
       "      <td>72.907814</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GqyNSPjMUTiV65wRe3BMb3</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>100</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.029609</td>\n",
       "      <td>0.010294</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>...</td>\n",
       "      <td>9.127914</td>\n",
       "      <td>0.879933</td>\n",
       "      <td>40.536236</td>\n",
       "      <td>4.116151</td>\n",
       "      <td>32</td>\n",
       "      <td>268.769232</td>\n",
       "      <td>156.522430</td>\n",
       "      <td>412.923551</td>\n",
       "      <td>214.694092</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fm8EnzZGQHxZfT3i6UK9L5</td>\n",
       "      <td>6</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.011536</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>291</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>...</td>\n",
       "      <td>6.870667</td>\n",
       "      <td>0.642977</td>\n",
       "      <td>24.568308</td>\n",
       "      <td>11.992144</td>\n",
       "      <td>70</td>\n",
       "      <td>76.572726</td>\n",
       "      <td>24.552498</td>\n",
       "      <td>129.200998</td>\n",
       "      <td>48.219223</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4F6aSdBKyJnEtkrPM32iCE</td>\n",
       "      <td>6</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.017636</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>...</td>\n",
       "      <td>6.536044</td>\n",
       "      <td>0.933677</td>\n",
       "      <td>18.579365</td>\n",
       "      <td>1.481332</td>\n",
       "      <td>144</td>\n",
       "      <td>106.675288</td>\n",
       "      <td>31.455770</td>\n",
       "      <td>162.725131</td>\n",
       "      <td>62.791615</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nKEB2xYLG2wUhFi4qZ2hPu</td>\n",
       "      <td>6</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.027333</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>...</td>\n",
       "      <td>11.222060</td>\n",
       "      <td>0.678201</td>\n",
       "      <td>26.312276</td>\n",
       "      <td>2.411977</td>\n",
       "      <td>65</td>\n",
       "      <td>246.105336</td>\n",
       "      <td>125.951302</td>\n",
       "      <td>393.237248</td>\n",
       "      <td>211.418961</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AoW6zDBkTBAMMEQYa6CbJk</td>\n",
       "      <td>4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.019985</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>183</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>...</td>\n",
       "      <td>8.867508</td>\n",
       "      <td>0.360216</td>\n",
       "      <td>18.778859</td>\n",
       "      <td>1.950196</td>\n",
       "      <td>82</td>\n",
       "      <td>110.610109</td>\n",
       "      <td>27.640871</td>\n",
       "      <td>155.047949</td>\n",
       "      <td>55.653294</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UnZG5BywtJjAzVWhGT5KW6</td>\n",
       "      <td>4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.032158</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>...</td>\n",
       "      <td>19.153255</td>\n",
       "      <td>0.297179</td>\n",
       "      <td>36.647420</td>\n",
       "      <td>0.946724</td>\n",
       "      <td>96</td>\n",
       "      <td>172.911552</td>\n",
       "      <td>99.865829</td>\n",
       "      <td>330.041016</td>\n",
       "      <td>196.268051</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cbJGEUS862wydVaGByoMbk</td>\n",
       "      <td>6</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>100</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.024986</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>...</td>\n",
       "      <td>21.922725</td>\n",
       "      <td>0.415735</td>\n",
       "      <td>32.786356</td>\n",
       "      <td>0.958393</td>\n",
       "      <td>84</td>\n",
       "      <td>165.253450</td>\n",
       "      <td>46.802063</td>\n",
       "      <td>281.259294</td>\n",
       "      <td>112.028191</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      UUID  rank encoder_hidden_layers  numepochs  \\\n",
       "0   RjoHq8UdW3nrGLVM7ypCwT     4            [100, 100]        200   \n",
       "1   2i5bqBnxRqbbBTQxTHv52L     4            [100, 100]        300   \n",
       "2   LEDBapbdDM3tEYbK2ewKgx     6            [100, 100]        300   \n",
       "3   UWFcU3QYqPW3M5DtEWUnRX     4        [200, 100, 50]        300   \n",
       "4   KzEqFfihqt86dAN2itm8sT     6            [100, 100]        200   \n",
       "5   GqyNSPjMUTiV65wRe3BMb3     4            [100, 100]        100   \n",
       "6   Fm8EnzZGQHxZfT3i6UK9L5     6        [200, 100, 50]        300   \n",
       "7   4F6aSdBKyJnEtkrPM32iCE     6        [200, 100, 50]        200   \n",
       "8   nKEB2xYLG2wUhFi4qZ2hPu     6            [100, 100]        100   \n",
       "9   AoW6zDBkTBAMMEQYa6CbJk     4        [200, 100, 50]        200   \n",
       "10  UnZG5BywtJjAzVWhGT5KW6     4        [200, 100, 50]        100   \n",
       "11  cbJGEUS862wydVaGByoMbk     6        [200, 100, 50]        100   \n",
       "\n",
       "    avg_recon_loss_tr  final_recon_loss_tr  avg_recon_loss_va  \\\n",
       "0            0.003137             0.000189           0.016616   \n",
       "1            0.002747             0.000190           0.016442   \n",
       "2            0.002153             0.000160           0.012588   \n",
       "3            0.002066             0.000167           0.013450   \n",
       "4            0.003298             0.000182           0.017321   \n",
       "5            0.006101             0.001256           0.029609   \n",
       "6            0.001747             0.000167           0.011536   \n",
       "7            0.002881             0.000268           0.017636   \n",
       "8            0.005863             0.000846           0.027333   \n",
       "9            0.003247             0.000206           0.019985   \n",
       "10           0.005904             0.001569           0.032158   \n",
       "11           0.004754             0.000288           0.024986   \n",
       "\n",
       "    best_recon_loss_va  bestep_recon_loss_va  avg_lin_loss_tr  ...  \\\n",
       "0             0.003628                   195         0.000171  ...   \n",
       "1             0.003932                   299         0.000140  ...   \n",
       "2             0.003156                   300         0.000141  ...   \n",
       "3             0.003439                   297         0.000246  ...   \n",
       "4             0.003852                   200         0.000223  ...   \n",
       "5             0.010294                   100         0.000137  ...   \n",
       "6             0.003469                   291         0.000390  ...   \n",
       "7             0.004320                   145         0.000392  ...   \n",
       "8             0.008082                   100         0.000441  ...   \n",
       "9             0.005011                   183         0.000704  ...   \n",
       "10            0.011976                   100         0.001215  ...   \n",
       "11            0.004503                   100         0.001964  ...   \n",
       "\n",
       "    avg_lin_anae_tr  final_lin_anae_tr  avg_lin_anae_va  best_lin_anae_va  \\\n",
       "0          5.749075           0.447996        12.580232          1.595680   \n",
       "1          6.168933           0.929518        32.996355          2.990858   \n",
       "2         19.242707           1.750130        66.426500          4.598801   \n",
       "3          4.595422           0.188614        18.033944          1.376639   \n",
       "4          7.635712           0.833945        26.515012          3.888892   \n",
       "5          9.127914           0.879933        40.536236          4.116151   \n",
       "6          6.870667           0.642977        24.568308         11.992144   \n",
       "7          6.536044           0.933677        18.579365          1.481332   \n",
       "8         11.222060           0.678201        26.312276          2.411977   \n",
       "9          8.867508           0.360216        18.778859          1.950196   \n",
       "10        19.153255           0.297179        36.647420          0.946724   \n",
       "11        21.922725           0.415735        32.786356          0.958393   \n",
       "\n",
       "    bestep_lin_anae_va  avg_pred_anae_tr  final_pred_anae_tr  \\\n",
       "0                   61        170.359142           41.137810   \n",
       "1                   35        129.926650           32.684006   \n",
       "2                   35        104.343127           28.304497   \n",
       "3                   75         73.100246           24.763781   \n",
       "4                   61        164.118183           37.730003   \n",
       "5                   32        268.769232          156.522430   \n",
       "6                   70         76.572726           24.552498   \n",
       "7                  144        106.675288           31.455770   \n",
       "8                   65        246.105336          125.951302   \n",
       "9                   82        110.610109           27.640871   \n",
       "10                  96        172.911552           99.865829   \n",
       "11                  84        165.253450           46.802063   \n",
       "\n",
       "    avg_pred_anae_va  best_pred_anae_va  bestep_pred_anae_va  \n",
       "0         369.384500         133.523148                  200  \n",
       "1         188.648688          64.504990                  297  \n",
       "2         203.419064          50.927658                  298  \n",
       "3         125.523613          53.717072                  294  \n",
       "4         261.344573          72.907814                  200  \n",
       "5         412.923551         214.694092                   55  \n",
       "6         129.200998          48.219223                  182  \n",
       "7         162.725131          62.791615                  196  \n",
       "8         393.237248         211.418961                  100  \n",
       "9         155.047949          55.653294                  193  \n",
       "10        330.041016         196.268051                   18  \n",
       "11        281.259294         112.028191                  100  \n",
       "\n",
       "[12 rows x 39 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df = pd.read_csv(os.path.join(output_folder, 'hyp_search_results.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains loss and ANAE statistics for all 12 runs, as `rank`, `encoder_hidden_layers`, and `numepochs` are swept. The statistics collected for each performance metric `perf` are:\n",
    "- `avg_perf_tr` - Average of metric for training data over all epochs.\n",
    "- `final_perf_tr` - Value of metric in last epoch of training data.\n",
    "\n",
    "If validation data is provided:\n",
    "- `avg_perf_va` - Average of metric for validation data over all epochs.\n",
    "- `best_perf_va` - Best value of metric for validation data over all epochs.\n",
    "- `bestep_perf_va` - Epoch at which best value of metric for validation data was obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 12 results from top to bottom are arranged from best to worst of the `sort_key` of `run_hyp_search()`, which is by default set to `'avg_total_loss_va'`. This is because total loss on validation data averaged across all epochs is an important metric for quantifying performance. Other important ones are `avg_pred_anae_va` and `avg_pred_loss_va`.\n",
    "\n",
    "Let's view this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>encoder_hidden_layers</th>\n",
       "      <th>numepochs</th>\n",
       "      <th>avg_total_loss_va</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>100</td>\n",
       "      <td>0.002441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank encoder_hidden_layers  numepochs  avg_total_loss_va\n",
       "0      4            [100, 100]        200           0.000513\n",
       "1      4            [100, 100]        300           0.000520\n",
       "2      6            [100, 100]        300           0.000572\n",
       "3      4        [200, 100, 50]        300           0.000607\n",
       "4      6            [100, 100]        200           0.000647\n",
       "5      4            [100, 100]        100           0.000730\n",
       "6      6        [200, 100, 50]        300           0.000765\n",
       "7      6        [200, 100, 50]        200           0.000829\n",
       "8      6            [100, 100]        100           0.000988\n",
       "9      4        [200, 100, 50]        200           0.001197\n",
       "10     4        [200, 100, 50]        100           0.001912\n",
       "11     6        [200, 100, 50]        100           0.002441"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truncated = df[['rank', 'encoder_hidden_layers', 'numepochs', 'avg_total_loss_va']]\n",
    "df_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from these results that `encoder_hidden_layers = [100, 100]` is clewrly doing better than `[200, 100, 50]`. Also, training for more epochs is generally better. These insights are very helpful in selecting a good combination of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignoring first few epochs\n",
    "Look back at the results in [`run.ipynb`](./run.ipynb). Notice how the performance is erratic for the first few epochs. As an example:\n",
    "<img src=\"./skewed_initial_epochs_example.png\" width=\"300\"/>\n",
    "\n",
    "A few erratic initial epochs can skew the average statistics significantly. This is why the `run_hyp_search()` method has an argument `avg_ignore_initial_epochs`, which specifies the number of initial epochs to ignore for average calculations. Let us set this to `100`, remove the 100 epoch option, and run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************************\n",
      "Starting StatePredictor hyperparameter search. Results will be stored in /Users/sourya/work/Essence/deep-koopman/examples/naca0012/hyp_search_7ZRpcFreheiqz5uCNNm3s9/hyp_search_results.csv.\n",
      "\n",
      "Performing total 8 runs. You can interrupt the script at any time (e.g. Ctrl+C), and intermediate results will be available in the above file.\n",
      "\n",
      "Log of the entire hyperpaameter search, as well as logs of failed StatePredictor runs will also be stored in the same folder.\n",
      "\n",
      "Hyperparameters' sweep ranges:\n",
      "rank : 4, 6\n",
      "encoded_size : 50\n",
      "encoder_hidden_layers : [100, 100], [200, 100, 50]\n",
      "numepochs : 200, 300\n",
      "weight_decay : 1e-05\n",
      "********************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 79.12it/s]\n",
      "100%|██████████| 300/300 [00:03<00:00, 78.43it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 74.33it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 73.24it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 75.98it/s]\n",
      "100%|██████████| 300/300 [00:03<00:00, 79.00it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 70.41it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 68.88it/s]\n",
      "100%|██████████| 8/8 [00:26<00:00,  3.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>encoder_hidden_layers</th>\n",
       "      <th>numepochs</th>\n",
       "      <th>avg_total_loss_va</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank encoder_hidden_layers  numepochs  avg_total_loss_va\n",
       "0     4        [200, 100, 50]        200           0.000102\n",
       "1     4            [100, 100]        200           0.000119\n",
       "2     6            [100, 100]        200           0.000121\n",
       "3     6            [100, 100]        300           0.000175\n",
       "4     6        [200, 100, 50]        200           0.000196\n",
       "5     6        [200, 100, 50]        300           0.000217\n",
       "6     4        [200, 100, 50]        300           0.000222\n",
       "7     4            [100, 100]        300           0.000334"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_options['numepochs'].remove(100)\n",
    "output_folder = run_hyp_search(\n",
    "    dh = dh,\n",
    "    hyp_options = hyp_options,\n",
    "    avg_ignore_initial_epochs = 100\n",
    ")\n",
    "\n",
    "df = pd.read_csv(os.path.join(output_folder, 'hyp_search_results.csv'))\n",
    "df_truncated = df[['rank', 'encoder_hidden_layers', 'numepochs', 'avg_total_loss_va']]\n",
    "df_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look better now, and are less sensitive to outlier epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlling the number of runs\n",
    "If you don't want to wait to run every possible configuration (which can exponentially explode as the number of options increase), you can control the number of runs using the `numruns` argument of `run_hyp_search()`. Setting this to less than the cardinality of the Cartesian product of all the values in `hyp_options` will randomly sample `numruns` runs.\n",
    "\n",
    "As an example, let's try sampling 5 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************************\n",
      "Starting StatePredictor hyperparameter search. Results will be stored in /Users/sourya/work/Essence/deep-koopman/examples/naca0012/hyp_search_92e7KQjuvk26VyqHGpZG3v/hyp_search_results.csv.\n",
      "\n",
      "Performing total 5 runs. You can interrupt the script at any time (e.g. Ctrl+C), and intermediate results will be available in the above file.\n",
      "\n",
      "Log of the entire hyperpaameter search, as well as logs of failed StatePredictor runs will also be stored in the same folder.\n",
      "\n",
      "Hyperparameters' sweep ranges:\n",
      "rank : 4, 6\n",
      "encoded_size : 50\n",
      "encoder_hidden_layers : [100, 100], [200, 100, 50]\n",
      "numepochs : 200, 300\n",
      "weight_decay : 1e-05\n",
      "********************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 71.13it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 69.00it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 73.94it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 69.04it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 72.12it/s]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.12s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>encoder_hidden_layers</th>\n",
       "      <th>numepochs</th>\n",
       "      <th>avg_total_loss_va</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank encoder_hidden_layers  numepochs  avg_total_loss_va\n",
       "0     6        [200, 100, 50]        200           0.000097\n",
       "1     6            [100, 100]        200           0.000118\n",
       "2     4        [200, 100, 50]        300           0.000140\n",
       "3     4        [200, 100, 50]        200           0.000141\n",
       "4     4            [100, 100]        200           0.000209"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder = run_hyp_search(\n",
    "    dh = dh,\n",
    "    hyp_options = hyp_options,\n",
    "    avg_ignore_initial_epochs = 100,\n",
    "    numruns = 5\n",
    ")\n",
    "\n",
    "df = pd.read_csv(os.path.join(output_folder, 'hyp_search_results.csv'))\n",
    "df_truncated = df[['rank', 'encoder_hidden_layers', 'numepochs', 'avg_total_loss_va']]\n",
    "df_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concluding thoughts\n",
    "We highly recommend performing hyperparameter search for any problem as it can lead to massively improved results. If required, you can perform several hundred or even several thousand runs, which can take several hours to run, but the results are usually worth it.\n",
    "\n",
    "Here's an example of an extensive hyperparameter search:\n",
    "```python\n",
    "output_folder = run_hyp_search(\n",
    "    dh = dh,\n",
    "    hyp_options = {\n",
    "        'rank': [3,6,8,10,20], #5 options\n",
    "        'num_encoded_states': [50,100,200,500,1000], #5 options\n",
    "        'encoder_hidden_layers': [\n",
    "            [100,100],[200,200],[500,500],\n",
    "            [50,100],[100,50],[100,200],[200,100],[200,500],[500,200],[500,1000],[1000,500],\n",
    "            [100,100,100],[200,200,200],[500,500,500],\n",
    "            [50,100,200],[200,100,50],[100,200,500],[500,200,100],[200,500,1000],[1000,500,200]\n",
    "        ], #20 options\n",
    "        'weight_decay': [0.,1e-6,1e-5,1e-4], #4 options\n",
    "        'decoder_loss_weight': [1e-3,1e-2,1e-1,1.], #4 options\n",
    "        'Kreg': [0.,1e-3,1e-2], #3 options\n",
    "        'clip_grad_norm': [None,5.,10.], #3 options\n",
    "        'clip_grad_value': [None,2.], #2 options\n",
    "    }, # total = 144,000 options\n",
    "    avg_ignore_initial_epochs = 100,\n",
    "    numruns = 3000 # randomly sample ~2% of the entire space\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
