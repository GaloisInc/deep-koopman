{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search on NACA0012 data\n",
    "Do this tutorial after [`run.ipynb`](./run.ipynb).\n",
    "\n",
    "You might be wondering how we arrived at the input configurations in the 'Optimizing' and the 'Improving run time' sections in `run.ipynb`. The method `deepk.hyp_search:run_hyp_search()` can perform hyperparameter search on either `StatePredictor` or `TrajectoryPredictor`. This sweeps the values of the different inputs to the class and its methods. Each configuration is trained and the loss and ANAE statistics across epochs recorded for training data (and validation data, if provided). These results can then be used to select 'good' input configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepk.hyp_search import run_hyp_search\n",
    "from deepk.state_predictor import StatePredictor_DataHandler\n",
    "from deepk import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of Data Handler we create determines the predictor model on which hyperparameter search is performed. In this case, we create a `StatePredictor_DataHandler`. This automatically sets the hyperparameter search to run on `StatePredictor` models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = StatePredictor_DataHandler(\n",
    "    Xtr=data['Xtr'], ttr=data['ttr'],\n",
    "    Xva=data['Xva'], tva=data['tva']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data handler is the only part that has to change when switching between `TrajectoryPredictor` and `StatePredictor`. Everything else in the hyperparameter search remains the same.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that test data is not used in hyperparameter search. It is highly recommended to provide validaion data, so that validation loss and ANAE statistics can also be collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an optional step used to seed the run. Since neural nets initialize their parameters randomly, setting the same random seed will ensure that your results are exactly the same as this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.set_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define options for hyperparameter search\n",
    "The `StatePredictor` class has possible inputs:\n",
    "- `dh`\n",
    "- `rank`\n",
    "- `encoded_size`\n",
    "- `encoder_hidden_layers`\n",
    "- `decoder_hidden_layers`\n",
    "- `batch_norm`\n",
    "\n",
    "Its `train_net()` method has possible inputs:\n",
    "- `numepochs`\n",
    "- `early_stopping`\n",
    "- `early_stopping_metric`\n",
    "- `lr`\n",
    "- `weight_decay`\n",
    "- `decoder_loss_weight`\n",
    "- `Kreg`\n",
    "- `cond_threshold`\n",
    "- `clip_grad_norm`\n",
    "- `clip_grad_value`\n",
    "\n",
    "All of these inputs, with the exception of `dh` already defined above, can be swept together in the hyperparameter search.\n",
    "\n",
    "For more on the inputs, see the [documentation of `StatePredictor`](htps://TODO).\n",
    "\n",
    "Let us define some values to sweep over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_options = {\n",
    "    'rank': 6, # 1 option\n",
    "    'encoder_hidden_layers': [ [200,200], [300,200,100] ], # 2 options\n",
    "    'numepochs': [200, 300, 400], # 3 options\n",
    "    'clip_grad_value': 2. # 1 option\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options that are not provided will revert to defaults."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run hyperparameter search\n",
    "Let us now run the hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: 'encoded_size' is a required argument to StatePredictor, so 'hyp_options' must include a key-value pair for {'encoded_size': <encoded_size_values>}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    run_hyp_search(\n",
    "        dh = dh,\n",
    "        hyp_options = hyp_options\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f'ValueError: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh, you got a `ValueError: 'encoded_size' is a required argument to StatePredictor, so 'hyp_options' must include a key-value pair for {'encoded_size': <encoded_size_values>}`. As it says, we need to specify one or more options for `encoded_size` since this is a required argument that does not have a default value. Let us specify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_options['encoded_size'] = [50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hyp_options` now has a total of 12 options = 2 for `'encoded_size'` times 2 for `'encoder_hidden_layers'` times 3 for `'numepochs'`.\n",
    "\n",
    "Let us run it again. This may take a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************************\n",
      "Starting StatePredictor hyperparameter search. Results will be stored in /Users/sourya/work/Essence/deep-koopman/examples/naca0012/hyp_search_55duKHWjD3tBEJ8KYFKUh8/hyp_search_results.csv.\n",
      "\n",
      "Performing total 12 runs. You can interrupt the script at any time (e.g. Ctrl+C), and intermediate results will be available in the above file.\n",
      "\n",
      "Log of the entire hyperparameter search, as well as logs of failed StatePredictor runs will also be stored in the same folder.\n",
      "\n",
      "Hyperparameters' sweep ranges:\n",
      "rank : 6\n",
      "encoded_size : 50, 100\n",
      "encoder_hidden_layers : [200, 200], [300, 200, 100]\n",
      "numepochs : 200, 300, 400\n",
      "clip_grad_value : 2.0\n",
      "********************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 72.48it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 71.85it/s]\n",
      "100%|██████████| 400/400 [00:05<00:00, 69.07it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 62.87it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 61.93it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 62.58it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 68.73it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 67.19it/s]\n",
      "100%|██████████| 400/400 [00:05<00:00, 67.26it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 62.05it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 62.46it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 62.02it/s]\n",
      "100%|██████████| 12/12 [00:55<00:00,  4.59s/it]\n"
     ]
    }
   ],
   "source": [
    "output_folder = run_hyp_search(\n",
    "    dh = dh,\n",
    "    hyp_options = hyp_options\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Hooray, it now runs successfully and returns a path to a folder. This contains a file `hyp_search_results.csv`. Let us open it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "      <th>encoded_size</th>\n",
       "      <th>encoder_hidden_layers</th>\n",
       "      <th>numepochs</th>\n",
       "      <th>avg_recon_loss_tr</th>\n",
       "      <th>final_recon_loss_tr</th>\n",
       "      <th>avg_recon_loss_va</th>\n",
       "      <th>best_recon_loss_va</th>\n",
       "      <th>bestep_recon_loss_va</th>\n",
       "      <th>avg_lin_loss_tr</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_lin_anae_tr</th>\n",
       "      <th>final_lin_anae_tr</th>\n",
       "      <th>avg_lin_anae_va</th>\n",
       "      <th>best_lin_anae_va</th>\n",
       "      <th>bestep_lin_anae_va</th>\n",
       "      <th>avg_pred_anae_tr</th>\n",
       "      <th>final_pred_anae_tr</th>\n",
       "      <th>avg_pred_anae_va</th>\n",
       "      <th>best_pred_anae_va</th>\n",
       "      <th>bestep_pred_anae_va</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iNnxrPZqsiVfattShWSJnt</td>\n",
       "      <td>100</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>400</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>6.831592e-07</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>322</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>...</td>\n",
       "      <td>3.213051</td>\n",
       "      <td>1.307821</td>\n",
       "      <td>7.096824</td>\n",
       "      <td>1.033443</td>\n",
       "      <td>87</td>\n",
       "      <td>49.102683</td>\n",
       "      <td>8.744789</td>\n",
       "      <td>78.046216</td>\n",
       "      <td>18.098024</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VNQ599h7fmwLxEabNiur4j</td>\n",
       "      <td>50</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>400</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>1.190653e-06</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>348</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>...</td>\n",
       "      <td>4.956933</td>\n",
       "      <td>19.861971</td>\n",
       "      <td>10.353928</td>\n",
       "      <td>1.190545</td>\n",
       "      <td>74</td>\n",
       "      <td>55.833751</td>\n",
       "      <td>7.745581</td>\n",
       "      <td>103.012294</td>\n",
       "      <td>23.051123</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9DdHdUXNvTZ42eAD9JKDJM</td>\n",
       "      <td>100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>400</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>9.123873e-07</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>380</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>...</td>\n",
       "      <td>3.210110</td>\n",
       "      <td>1.320593</td>\n",
       "      <td>12.178429</td>\n",
       "      <td>2.085934</td>\n",
       "      <td>121</td>\n",
       "      <td>65.876381</td>\n",
       "      <td>11.496212</td>\n",
       "      <td>113.172444</td>\n",
       "      <td>26.812935</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h5Duqb498YYPmMu52ZFFgx</td>\n",
       "      <td>50</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>400</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>5.487989e-06</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>371</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>...</td>\n",
       "      <td>9.266469</td>\n",
       "      <td>5.436409</td>\n",
       "      <td>35.501688</td>\n",
       "      <td>2.204152</td>\n",
       "      <td>78</td>\n",
       "      <td>72.703215</td>\n",
       "      <td>19.305519</td>\n",
       "      <td>114.892749</td>\n",
       "      <td>31.420439</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHbzxwzFYJ9HMUNxGnjsGH</td>\n",
       "      <td>100</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>1.065168e-06</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>287</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>...</td>\n",
       "      <td>4.594642</td>\n",
       "      <td>0.739944</td>\n",
       "      <td>29.717091</td>\n",
       "      <td>1.661546</td>\n",
       "      <td>207</td>\n",
       "      <td>61.990227</td>\n",
       "      <td>7.649416</td>\n",
       "      <td>123.586224</td>\n",
       "      <td>26.376110</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Qh8KpbR9TdBrV8RkdyH3q2</td>\n",
       "      <td>50</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>3.126138e-06</td>\n",
       "      <td>0.005544</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>274</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>...</td>\n",
       "      <td>3.245654</td>\n",
       "      <td>0.788686</td>\n",
       "      <td>17.093329</td>\n",
       "      <td>1.379037</td>\n",
       "      <td>137</td>\n",
       "      <td>65.601783</td>\n",
       "      <td>9.741706</td>\n",
       "      <td>125.932823</td>\n",
       "      <td>30.363571</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FjP9gswbejuxhv39ey5zXv</td>\n",
       "      <td>100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>1.288227e-05</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>299</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>...</td>\n",
       "      <td>8.077429</td>\n",
       "      <td>6.767651</td>\n",
       "      <td>42.054641</td>\n",
       "      <td>2.216914</td>\n",
       "      <td>85</td>\n",
       "      <td>96.714408</td>\n",
       "      <td>23.684887</td>\n",
       "      <td>143.633718</td>\n",
       "      <td>33.752071</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5yQdBb3mw9ZTSmVWcHcU5Q</td>\n",
       "      <td>50</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>2.282682e-06</td>\n",
       "      <td>0.007165</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>154</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>...</td>\n",
       "      <td>7.040722</td>\n",
       "      <td>1.878384</td>\n",
       "      <td>21.883381</td>\n",
       "      <td>1.364759</td>\n",
       "      <td>67</td>\n",
       "      <td>92.357070</td>\n",
       "      <td>12.237989</td>\n",
       "      <td>146.667590</td>\n",
       "      <td>33.520821</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9QzfMJoFUzT6mKNo7o6Dcj</td>\n",
       "      <td>100</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>1.678960e-06</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>199</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>...</td>\n",
       "      <td>5.635093</td>\n",
       "      <td>0.556354</td>\n",
       "      <td>12.895879</td>\n",
       "      <td>1.357195</td>\n",
       "      <td>99</td>\n",
       "      <td>87.150974</td>\n",
       "      <td>11.498751</td>\n",
       "      <td>149.739165</td>\n",
       "      <td>22.095259</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8bW9GKnReq2bTiJRAP79yt</td>\n",
       "      <td>100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>5.191852e-06</td>\n",
       "      <td>0.007210</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>186</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>...</td>\n",
       "      <td>4.372336</td>\n",
       "      <td>0.951696</td>\n",
       "      <td>15.026154</td>\n",
       "      <td>2.647733</td>\n",
       "      <td>172</td>\n",
       "      <td>114.426364</td>\n",
       "      <td>20.360687</td>\n",
       "      <td>149.997272</td>\n",
       "      <td>34.385357</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MWn7LuV8pywm2EEzFWawi4</td>\n",
       "      <td>50</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>1.272344e-05</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>293</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>...</td>\n",
       "      <td>6.500367</td>\n",
       "      <td>2.929357</td>\n",
       "      <td>26.757030</td>\n",
       "      <td>4.467119</td>\n",
       "      <td>71</td>\n",
       "      <td>99.418912</td>\n",
       "      <td>21.294147</td>\n",
       "      <td>158.856712</td>\n",
       "      <td>44.118656</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ppw7b8ZgAnxxakmyroitHr</td>\n",
       "      <td>50</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>4.848288e-06</td>\n",
       "      <td>0.007920</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>199</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>3.254115</td>\n",
       "      <td>1.298429</td>\n",
       "      <td>11.536693</td>\n",
       "      <td>2.225611</td>\n",
       "      <td>103</td>\n",
       "      <td>111.111557</td>\n",
       "      <td>17.602318</td>\n",
       "      <td>227.974021</td>\n",
       "      <td>36.776321</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      UUID  encoded_size encoder_hidden_layers  numepochs  \\\n",
       "0   iNnxrPZqsiVfattShWSJnt           100       [300, 200, 100]        400   \n",
       "1   VNQ599h7fmwLxEabNiur4j            50       [300, 200, 100]        400   \n",
       "2   9DdHdUXNvTZ42eAD9JKDJM           100            [200, 200]        400   \n",
       "3   h5Duqb498YYPmMu52ZFFgx            50            [200, 200]        400   \n",
       "4   SHbzxwzFYJ9HMUNxGnjsGH           100       [300, 200, 100]        300   \n",
       "5   Qh8KpbR9TdBrV8RkdyH3q2            50       [300, 200, 100]        300   \n",
       "6   FjP9gswbejuxhv39ey5zXv           100            [200, 200]        300   \n",
       "7   5yQdBb3mw9ZTSmVWcHcU5Q            50       [300, 200, 100]        200   \n",
       "8   9QzfMJoFUzT6mKNo7o6Dcj           100       [300, 200, 100]        200   \n",
       "9   8bW9GKnReq2bTiJRAP79yt           100            [200, 200]        200   \n",
       "10  MWn7LuV8pywm2EEzFWawi4            50            [200, 200]        300   \n",
       "11  Ppw7b8ZgAnxxakmyroitHr            50            [200, 200]        200   \n",
       "\n",
       "    avg_recon_loss_tr  final_recon_loss_tr  avg_recon_loss_va  \\\n",
       "0            0.000662         6.831592e-07           0.003407   \n",
       "1            0.000685         1.190653e-06           0.003589   \n",
       "2            0.000781         9.123873e-07           0.003476   \n",
       "3            0.000932         5.487989e-06           0.004780   \n",
       "4            0.000990         1.065168e-06           0.005076   \n",
       "5            0.001008         3.126138e-06           0.005544   \n",
       "6            0.001125         1.288227e-05           0.005652   \n",
       "7            0.001393         2.282682e-06           0.007165   \n",
       "8            0.001396         1.678960e-06           0.006861   \n",
       "9            0.001553         5.191852e-06           0.007210   \n",
       "10           0.001141         1.272344e-05           0.006043   \n",
       "11           0.001597         4.848288e-06           0.007920   \n",
       "\n",
       "    best_recon_loss_va  bestep_recon_loss_va  avg_lin_loss_tr  ...  \\\n",
       "0             0.000135                   322         0.000077  ...   \n",
       "1             0.000160                   348         0.000087  ...   \n",
       "2             0.000135                   380         0.000036  ...   \n",
       "3             0.000445                   371         0.000057  ...   \n",
       "4             0.000099                   287         0.000160  ...   \n",
       "5             0.000278                   274         0.000052  ...   \n",
       "6             0.000382                   299         0.000081  ...   \n",
       "7             0.000248                   154         0.000245  ...   \n",
       "8             0.000217                   199         0.000174  ...   \n",
       "9             0.000278                   186         0.000039  ...   \n",
       "10            0.000620                   293         0.000061  ...   \n",
       "11            0.000281                   199         0.000043  ...   \n",
       "\n",
       "    avg_lin_anae_tr  final_lin_anae_tr  avg_lin_anae_va  best_lin_anae_va  \\\n",
       "0          3.213051           1.307821         7.096824          1.033443   \n",
       "1          4.956933          19.861971        10.353928          1.190545   \n",
       "2          3.210110           1.320593        12.178429          2.085934   \n",
       "3          9.266469           5.436409        35.501688          2.204152   \n",
       "4          4.594642           0.739944        29.717091          1.661546   \n",
       "5          3.245654           0.788686        17.093329          1.379037   \n",
       "6          8.077429           6.767651        42.054641          2.216914   \n",
       "7          7.040722           1.878384        21.883381          1.364759   \n",
       "8          5.635093           0.556354        12.895879          1.357195   \n",
       "9          4.372336           0.951696        15.026154          2.647733   \n",
       "10         6.500367           2.929357        26.757030          4.467119   \n",
       "11         3.254115           1.298429        11.536693          2.225611   \n",
       "\n",
       "    bestep_lin_anae_va  avg_pred_anae_tr  final_pred_anae_tr  \\\n",
       "0                   87         49.102683            8.744789   \n",
       "1                   74         55.833751            7.745581   \n",
       "2                  121         65.876381           11.496212   \n",
       "3                   78         72.703215           19.305519   \n",
       "4                  207         61.990227            7.649416   \n",
       "5                  137         65.601783            9.741706   \n",
       "6                   85         96.714408           23.684887   \n",
       "7                   67         92.357070           12.237989   \n",
       "8                   99         87.150974           11.498751   \n",
       "9                  172        114.426364           20.360687   \n",
       "10                  71         99.418912           21.294147   \n",
       "11                 103        111.111557           17.602318   \n",
       "\n",
       "    avg_pred_anae_va  best_pred_anae_va  bestep_pred_anae_va  \n",
       "0          78.046216          18.098024                  356  \n",
       "1         103.012294          23.051123                  391  \n",
       "2         113.172444          26.812935                  368  \n",
       "3         114.892749          31.420439                  396  \n",
       "4         123.586224          26.376110                  292  \n",
       "5         125.932823          30.363571                  288  \n",
       "6         143.633718          33.752071                  206  \n",
       "7         146.667590          33.520821                  200  \n",
       "8         149.739165          22.095259                  189  \n",
       "9         149.997272          34.385357                  199  \n",
       "10        158.856712          44.118656                  300  \n",
       "11        227.974021          36.776321                  161  \n",
       "\n",
       "[12 rows x 39 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df = pd.read_csv(os.path.join(output_folder, 'hyp_search_results.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains loss and ANAE statistics for all 12 runs, as `encoded_size`, `encoder_hidden_layers`, and `numepochs` are swept. The statistics collected for each performance metric `<perf>` are:\n",
    "- `avg_<perf>_tr` - Average of metric for training data over all epochs.\n",
    "- `final_<perf>_tr` - Value of metric in last epoch of training data.\n",
    "\n",
    "If validation data is provided:\n",
    "- `avg_<perf>_va` - Average of metric for validation data over all epochs.\n",
    "- `best_<perf>_va` - Best value of metric for validation data over all epochs.\n",
    "- `bestep_<perf>_va` - Epoch at which best value of metric for validation data was obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 12 results from top to bottom are arranged from best to worst of the `sort_key` of `run_hyp_search()`, which is by default set to `'avg_pred_anae_va'`. This is because prediction ANAE of validation data averaged across all epochs is an important metric for quantifying performance.\n",
    "\n",
    "Let's view this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_size</th>\n",
       "      <th>encoder_hidden_layers</th>\n",
       "      <th>numepochs</th>\n",
       "      <th>avg_pred_anae_va</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>400</td>\n",
       "      <td>78.046216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>400</td>\n",
       "      <td>103.012294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>400</td>\n",
       "      <td>113.172444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>400</td>\n",
       "      <td>114.892749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>300</td>\n",
       "      <td>123.586224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>300</td>\n",
       "      <td>125.932823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>300</td>\n",
       "      <td>143.633718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>146.667590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>149.739165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>200</td>\n",
       "      <td>149.997272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>300</td>\n",
       "      <td>158.856712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>200</td>\n",
       "      <td>227.974021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    encoded_size encoder_hidden_layers  numepochs  avg_pred_anae_va\n",
       "0            100       [300, 200, 100]        400         78.046216\n",
       "1             50       [300, 200, 100]        400        103.012294\n",
       "2            100            [200, 200]        400        113.172444\n",
       "3             50            [200, 200]        400        114.892749\n",
       "4            100       [300, 200, 100]        300        123.586224\n",
       "5             50       [300, 200, 100]        300        125.932823\n",
       "6            100            [200, 200]        300        143.633718\n",
       "7             50       [300, 200, 100]        200        146.667590\n",
       "8            100       [300, 200, 100]        200        149.739165\n",
       "9            100            [200, 200]        200        149.997272\n",
       "10            50            [200, 200]        300        158.856712\n",
       "11            50            [200, 200]        200        227.974021"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truncated = df[['encoded_size', 'encoder_hidden_layers', 'numepochs', 'avg_pred_anae_va']]\n",
    "df_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignoring first few epochs\n",
    "The ANAE values above are really high. This is because the performance is erratic early on, before settling down. You can also see this by looking back at the results in [`run.ipynb`](./run.ipynb):\n",
    "\n",
    "<img src=\"./skewed_initial_epochs_example.png\" width=\"300\"/>\n",
    "\n",
    "A few erratic initial epochs can skew the average statistics significantly. This is why the `run_hyp_search()` method has an argument `avg_ignore_initial_epochs`, which specifies the number of initial epochs to ignore for average calculations. Let us set this to `100`, so that averaging starts from the 100th epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************************\n",
      "Starting StatePredictor hyperparameter search. Results will be stored in /Users/sourya/work/Essence/deep-koopman/examples/naca0012/hyp_search_9F87fXxvyyckxba7qX57Tq/hyp_search_results.csv.\n",
      "\n",
      "Performing total 12 runs. You can interrupt the script at any time (e.g. Ctrl+C), and intermediate results will be available in the above file.\n",
      "\n",
      "Log of the entire hyperparameter search, as well as logs of failed StatePredictor runs will also be stored in the same folder.\n",
      "\n",
      "Hyperparameters' sweep ranges:\n",
      "rank : 6\n",
      "encoded_size : 50, 100\n",
      "encoder_hidden_layers : [200, 200], [300, 200, 100]\n",
      "numepochs : 200, 300, 400\n",
      "clip_grad_value : 2.0\n",
      "********************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 70.89it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 71.24it/s]\n",
      "100%|██████████| 400/400 [00:05<00:00, 72.04it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 64.60it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 64.54it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 65.02it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 69.70it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 70.25it/s]\n",
      "100%|██████████| 400/400 [00:05<00:00, 68.79it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 62.57it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 60.72it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 61.78it/s]\n",
      "100%|██████████| 12/12 [00:54<00:00,  4.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_size</th>\n",
       "      <th>encoder_hidden_layers</th>\n",
       "      <th>numepochs</th>\n",
       "      <th>avg_pred_anae_va</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>400</td>\n",
       "      <td>30.929258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>400</td>\n",
       "      <td>37.337053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>37.530303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>300</td>\n",
       "      <td>43.026576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>400</td>\n",
       "      <td>48.322604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>48.949412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>200</td>\n",
       "      <td>54.143983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>300</td>\n",
       "      <td>55.724311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>300</td>\n",
       "      <td>64.380776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>400</td>\n",
       "      <td>67.268883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>200</td>\n",
       "      <td>69.619269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>300</td>\n",
       "      <td>78.091877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    encoded_size encoder_hidden_layers  numepochs  avg_pred_anae_va\n",
       "0            100       [300, 200, 100]        400         30.929258\n",
       "1             50       [300, 200, 100]        400         37.337053\n",
       "2            100       [300, 200, 100]        200         37.530303\n",
       "3            100       [300, 200, 100]        300         43.026576\n",
       "4            100            [200, 200]        400         48.322604\n",
       "5             50       [300, 200, 100]        200         48.949412\n",
       "6            100            [200, 200]        200         54.143983\n",
       "7             50       [300, 200, 100]        300         55.724311\n",
       "8            100            [200, 200]        300         64.380776\n",
       "9             50            [200, 200]        400         67.268883\n",
       "10            50            [200, 200]        200         69.619269\n",
       "11            50            [200, 200]        300         78.091877"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.set_seed(10)\n",
    "\n",
    "output_folder = run_hyp_search(\n",
    "    dh = dh,\n",
    "    hyp_options = hyp_options,\n",
    "    avg_ignore_initial_epochs = 100\n",
    ")\n",
    "\n",
    "df = pd.read_csv(os.path.join(output_folder, 'hyp_search_results.csv'))\n",
    "df_truncated = df[['encoded_size', 'encoder_hidden_layers', 'numepochs', 'avg_pred_anae_va']]\n",
    "df_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look a lot better now, since they are less sensitive to outlier epochs. You can see from these results that `encoder_hidden_layers = [300, 200, 100]` is doing better than `[200, 200]`. These insights are very helpful in selecting a good combination of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlling the number of runs\n",
    "If you don't want to wait to run every possible configuration (which can exponentially explode as the number of options increase), you can control the number of runs using the `numruns` argument of `run_hyp_search()`. Let us set this to 5. This will randomly sample 5 runs out of the total of 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************************\n",
      "Starting StatePredictor hyperparameter search. Results will be stored in /Users/sourya/work/Essence/deep-koopman/examples/naca0012/hyp_search_AQLMLHcZKUYGM6c5qoDMQS/hyp_search_results.csv.\n",
      "\n",
      "Performing total 5 runs. You can interrupt the script at any time (e.g. Ctrl+C), and intermediate results will be available in the above file.\n",
      "\n",
      "Log of the entire hyperparameter search, as well as logs of failed StatePredictor runs will also be stored in the same folder.\n",
      "\n",
      "Hyperparameters' sweep ranges:\n",
      "rank : 6\n",
      "encoded_size : 50, 100\n",
      "encoder_hidden_layers : [200, 200], [300, 200, 100]\n",
      "numepochs : 200, 300, 400\n",
      "clip_grad_value : 2.0\n",
      "********************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 68.03it/s]\n",
      "100%|██████████| 300/300 [00:04<00:00, 70.57it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 64.91it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 65.07it/s]\n",
      "100%|██████████| 400/400 [00:05<00:00, 72.74it/s]\n",
      "100%|██████████| 5/5 [00:21<00:00,  4.39s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_size</th>\n",
       "      <th>encoder_hidden_layers</th>\n",
       "      <th>numepochs</th>\n",
       "      <th>avg_pred_anae_va</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>400</td>\n",
       "      <td>25.391461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>[300, 200, 100]</td>\n",
       "      <td>200</td>\n",
       "      <td>39.539752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>300</td>\n",
       "      <td>41.807985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>400</td>\n",
       "      <td>65.512063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>200</td>\n",
       "      <td>76.329162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encoded_size encoder_hidden_layers  numepochs  avg_pred_anae_va\n",
       "0            50       [300, 200, 100]        400         25.391461\n",
       "1           100       [300, 200, 100]        200         39.539752\n",
       "2           100            [200, 200]        300         41.807985\n",
       "3            50            [200, 200]        400         65.512063\n",
       "4           100            [200, 200]        200         76.329162"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.set_seed(10)\n",
    "\n",
    "output_folder = run_hyp_search(\n",
    "    dh = dh,\n",
    "    hyp_options = hyp_options,\n",
    "    avg_ignore_initial_epochs = 100,\n",
    "    numruns = 5\n",
    ")\n",
    "\n",
    "df = pd.read_csv(os.path.join(output_folder, 'hyp_search_results.csv'))\n",
    "df_truncated = df[['encoded_size', 'encoder_hidden_layers', 'numepochs', 'avg_pred_anae_va']]\n",
    "df_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance vs time tradeoff\n",
    "We highly recommend performing hyperparameter search for any problem as it can lead to massively improved results (we got $<7\\%$ prediction ANAE in [`run.ipynb`](./run.ipynb)!). The longer you perform a hyperparameter search for, the more likely you are to get good results. If required, you can perform several hundred or even several thousand runs, which can take time to run, but the results are usually worth it.\n",
    "\n",
    "Here's an example of an extensive hyperparameter search:\n",
    "```python\n",
    "output_folder = run_hyp_search(\n",
    "    dh = dh,\n",
    "    hyp_options = {\n",
    "        'rank': [3,6,8,10,20], #5 options\n",
    "        'num_encoded_states': [50,100,200,500,1000], #5 options\n",
    "        'encoder_hidden_layers': [\n",
    "            [100,100],[200,200],[500,500],\n",
    "            [50,100],[100,50],[100,200],[200,100],[200,500],[500,200],[500,1000],[1000,500],\n",
    "            [100,100,100],[200,200,200],[500,500,500],\n",
    "            [50,100,200],[200,100,50],[100,200,500],[500,200,100],[200,500,1000],[1000,500,200]\n",
    "        ], #20 options\n",
    "        'weight_decay': [0.,1e-6,1e-5,1e-4], #4 options\n",
    "        'Kreg': [0.,1e-3,1e-2], #3 options\n",
    "        'clip_grad_norm': [None,5.,10.], #3 options\n",
    "        'clip_grad_value': [None,2.], #2 options\n",
    "    }, # total = 36,000 options\n",
    "    avg_ignore_initial_epochs = 100,\n",
    "    numruns = 3600 # randomly sample 10% of the entire space\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on `decoder_loss_weight`\n",
    "Since `decoder_loss_weight` is an input to `train_net()`, it is a valid key for `hyp_options`. However, note that changing `decoder_loss_weight` will change the scale of the loss function, so it won't be fair any more to compare the loss matrics across configurations with different values of `decoder_loss_weight`. The ANAE metrics can still be compared across all configurations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
